{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ERN",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1HStgqNitUHcr5_OmnGlx_p_SFTl4DZH8",
      "authorship_tag": "ABX9TyO12gbXtOioimjEv6IjvWA8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kurogo-nguyen/ern/blob/main/ERN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "wqenka6uQ7hW",
        "outputId": "2953f9c5-9a57-4dc4-c16b-10e05f007ac1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.7/dist-packages (0.24.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from mne) (1.21.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from mne) (1.4.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install mne"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "nLQd41R2wtSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mne\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Activation, Permute, Dropout\n",
        "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
        "from keras.layers import SeparableConv2D, DepthwiseConv2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Input, Flatten\n",
        "from keras.constraints import max_norm\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import utils as np_utils\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "xta4kphDu50S"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Def func"
      ],
      "metadata": {
        "id": "E-8b3o8Lyqy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/drive/MyDrive/ERN-Data/' #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "7LpKG95Li_Yc"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loadData(id):\n",
        "    id=str(id).zfill(3)\n",
        "    raw = mne.io.read_raw(f'{data_path}/sub-{id}/eeg/sub-{id}_task-ERN_eeg.set')\n",
        "    \n",
        "    return raw"
      ],
      "metadata": {
        "id": "gceB8BFfyqgt"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ],
      "metadata": {
        "id": "Htovm2FLyuaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw = mne.io.read_raw(\"/content/drive/MyDrive/ERN-Data/sub-006/eeg/sub-006_task-ERN_eeg.set\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddoxh5mzw7ef",
        "outputId": "6de64c9b-59c7-4ca7-9208-ef66ed36ca35"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading /content/drive/MyDrive/ERN-Data/sub-006/eeg/sub-006_task-ERN_eeg.fdt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw.info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "Om7JUJKmxKi4",
        "outputId": "6b9d4771-740e-420a-de8e-8deb39a98f9a"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
              "    <tr>\n",
              "        <th>Measurement date</th>\n",
              "<td>Unknown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "        <th>Experimenter</th>\n",
              "<td>Unknown</td>\n",
              "    </tr>\n",
              "        <th>Participant</th>\n",
              "<td>Unknown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "        <th>Digitized points</th>\n",
              "        <td>Not available</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "        <th>Good channels</th>\n",
              "        <td>33 EEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "        <th>Bad channels</th>\n",
              "        <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "        <th>EOG channels</th>\n",
              "        <td>Not available</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "        <th>ECG channels</th>\n",
              "        <td>Not available</td>\n",
              "    <tr>\n",
              "        <th>Sampling frequency</th>\n",
              "        <td>1024.00 Hz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "        <th>Highpass</th>\n",
              "        <td>0.00 Hz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "        <th>Lowpass</th>\n",
              "        <td>512.00 Hz</td>\n",
              "    </tr>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<Info | 7 non-empty values\n",
              " bads: []\n",
              " ch_names: FP1, F3, F7, FC3, C3, C5, P3, P7, P9, PO7, PO3, O1, Oz, Pz, CPz, ...\n",
              " chs: 33 EEG\n",
              " custom_ref_applied: False\n",
              " highpass: 0.0 Hz\n",
              " lowpass: 512.0 Hz\n",
              " meas_date: unspecified\n",
              " nchan: 33\n",
              " projs: []\n",
              " sfreq: 1024.0 Hz\n",
              ">"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_events, all_event_id = mne.events_from_annotations(raw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fseBQv2t0L0h",
        "outputId": "090df40b-ceaf-418e-beef-3a930e8a6011"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Used Annotations descriptions: ['11', '111', '112', '12', '121', '122', '21', '211', '212', '22', '221', '222']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" response - flanker - target\n",
        "    1: left/compatible\n",
        "    2: right/incompatible\n",
        "\"\"\"\n",
        "\n",
        "correct_response = ['111', '121',          # respones: left  - target: left\n",
        "                    '212', '222',]         # respones: right - target: right\n",
        "\n",
        "incorrect_response = ['112', '122',         # respones: left  - target: right\n",
        "                     '211', '221',]         # respones: right - target: left"
      ],
      "metadata": {
        "id": "CFBzTSoGvdFy"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-Process"
      ],
      "metadata": {
        "id": "1mp0Y3T9yxrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getData(raw, pick_channels=['Fz'], metadata_tmin=-1, metadata_tmax=1, \n",
        "            epochs_tmin=-0.4, epochs_tmax=0.6, baseline=(-0.4, -0.2)):\n",
        "    \n",
        "    metadata, events, event_id = mne.epochs.make_metadata(events=all_events, \n",
        "                                                          event_id=all_event_id,\n",
        "                                                          tmin=metadata_tmin, \n",
        "                                                          tmax=metadata_tmax, \n",
        "                                                          sfreq=raw.info['sfreq'],\n",
        "                                                          row_events=row_events,)\n",
        "    \n",
        "    metadata['response_correct']=False\n",
        "    metadata.loc[metadata['event_name'].isin(correct_response), 'response_correct'] = True\n",
        "    reject = {'eeg': 250e-6}\n",
        "    epochs = mne.Epochs(raw=raw, tmin=epochs_tmin, tmax=epochs_tmax,\n",
        "                        baseline=baseline, \n",
        "                        events=events, event_id=event_id, metadata=metadata,\n",
        "                        reject=reject,\n",
        "                        preload=True)\n",
        "    \n",
        "    epochs.pick_channels(pick_channels)\n",
        "    X = epochs.get_data()\n",
        "    y = (epochs.metadata.response_correct*1).to_numpy()\n",
        "\n",
        "    return X,y"
      ],
      "metadata": {
        "id": "E-22klJyfbTo"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1bNeSW0qirjf"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadata_tmin, metadata_tmax = -1, 1\n",
        "row_events = correct_response + incorrect_response\n",
        "\n",
        "metadata, events, event_id = mne.epochs.make_metadata(\n",
        "    events=all_events, event_id=all_event_id,\n",
        "    tmin=metadata_tmin, tmax=metadata_tmax, sfreq=raw.info['sfreq'],\n",
        "    row_events=row_events,\n",
        ")\n",
        "metadata"
      ],
      "metadata": {
        "id": "vD5D-skWxMJE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "f46a4350-7335-4f22-b207-6f816301c981"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3ee2a8a1-81ea-4e7b-a512-e029dceed7c4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>event_name</th>\n",
              "      <th>11</th>\n",
              "      <th>111</th>\n",
              "      <th>112</th>\n",
              "      <th>12</th>\n",
              "      <th>121</th>\n",
              "      <th>122</th>\n",
              "      <th>21</th>\n",
              "      <th>211</th>\n",
              "      <th>212</th>\n",
              "      <th>22</th>\n",
              "      <th>221</th>\n",
              "      <th>222</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>121</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>122</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.370117</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>122</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.267578</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>111</td>\n",
              "      <td>-0.326172</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>222</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.297852</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>775</th>\n",
              "      <td>212</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.304688</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>777</th>\n",
              "      <td>111</td>\n",
              "      <td>-0.258789</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>779</th>\n",
              "      <td>111</td>\n",
              "      <td>-0.278320</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>781</th>\n",
              "      <td>121</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.360352</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>783</th>\n",
              "      <td>212</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.301758</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>388 rows × 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ee2a8a1-81ea-4e7b-a512-e029dceed7c4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3ee2a8a1-81ea-4e7b-a512-e029dceed7c4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3ee2a8a1-81ea-4e7b-a512-e029dceed7c4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    event_name        11  111  112        12  ...  211  212        22  221  222\n",
              "0          121       NaN  NaN  NaN       NaN  ...  NaN  NaN       NaN  NaN  NaN\n",
              "2          122       NaN  NaN  NaN       NaN  ...  NaN  NaN -0.370117  NaN  NaN\n",
              "4          122       NaN  NaN  NaN       NaN  ...  NaN  NaN -0.267578  NaN  NaN\n",
              "6          111 -0.326172  0.0  NaN       NaN  ...  NaN  NaN       NaN  NaN  NaN\n",
              "8          222       NaN  NaN  NaN       NaN  ...  NaN  NaN -0.297852  NaN  0.0\n",
              "..         ...       ...  ...  ...       ...  ...  ...  ...       ...  ...  ...\n",
              "775        212       NaN  NaN  NaN -0.304688  ...  NaN  0.0       NaN  NaN  NaN\n",
              "777        111 -0.258789  0.0  NaN       NaN  ...  NaN  NaN       NaN  NaN  NaN\n",
              "779        111 -0.278320  0.0  NaN       NaN  ...  NaN  NaN       NaN  NaN  NaN\n",
              "781        121       NaN  NaN  NaN       NaN  ...  NaN  NaN       NaN  NaN  NaN\n",
              "783        212       NaN  NaN  NaN -0.301758  ...  NaN  0.0       NaN  NaN  NaN\n",
              "\n",
              "[388 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metadata['response_correct']=False\n",
        "metadata.loc[metadata['event_name'].isin(correct_response), 'response_correct'] = True\n",
        "metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "RowYwTmvWtJF",
        "outputId": "c1be02d7-78a5-4e1e-e17e-e6cc9fe64afb"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-29738626-42aa-4d55-9a1a-32db234a2335\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>event_name</th>\n",
              "      <th>11</th>\n",
              "      <th>111</th>\n",
              "      <th>112</th>\n",
              "      <th>12</th>\n",
              "      <th>121</th>\n",
              "      <th>122</th>\n",
              "      <th>21</th>\n",
              "      <th>211</th>\n",
              "      <th>212</th>\n",
              "      <th>22</th>\n",
              "      <th>221</th>\n",
              "      <th>222</th>\n",
              "      <th>response_correct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>121</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>122</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.370117</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>122</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.267578</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>111</td>\n",
              "      <td>-0.326172</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>222</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.297852</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>775</th>\n",
              "      <td>212</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.304688</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>777</th>\n",
              "      <td>111</td>\n",
              "      <td>-0.258789</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>779</th>\n",
              "      <td>111</td>\n",
              "      <td>-0.278320</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>781</th>\n",
              "      <td>121</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.360352</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>783</th>\n",
              "      <td>212</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.301758</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>388 rows × 14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29738626-42aa-4d55-9a1a-32db234a2335')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-29738626-42aa-4d55-9a1a-32db234a2335 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-29738626-42aa-4d55-9a1a-32db234a2335');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    event_name        11  111  112  ...        22  221  222  response_correct\n",
              "0          121       NaN  NaN  NaN  ...       NaN  NaN  NaN              True\n",
              "2          122       NaN  NaN  NaN  ... -0.370117  NaN  NaN             False\n",
              "4          122       NaN  NaN  NaN  ... -0.267578  NaN  NaN             False\n",
              "6          111 -0.326172  0.0  NaN  ...       NaN  NaN  NaN              True\n",
              "8          222       NaN  NaN  NaN  ... -0.297852  NaN  0.0              True\n",
              "..         ...       ...  ...  ...  ...       ...  ...  ...               ...\n",
              "775        212       NaN  NaN  NaN  ...       NaN  NaN  NaN              True\n",
              "777        111 -0.258789  0.0  NaN  ...       NaN  NaN  NaN              True\n",
              "779        111 -0.278320  0.0  NaN  ...       NaN  NaN  NaN              True\n",
              "781        121       NaN  NaN  NaN  ...       NaN  NaN  NaN              True\n",
              "783        212       NaN  NaN  NaN  ...       NaN  NaN  NaN              True\n",
              "\n",
              "[388 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_tmin, epochs_tmax = -0.4, 0.6\n",
        "baseline = (-0.4, -0.2)\n",
        "# reject = {'eeg': 250e-6}\n",
        "epochs = mne.Epochs(raw=raw, tmin=epochs_tmin, tmax=epochs_tmax,\n",
        "                    baseline=baseline, \n",
        "                    # reject=reject,\n",
        "                    events=events, event_id=event_id, metadata=metadata,\n",
        "                    preload=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0YV9Zpu__Ri",
        "outputId": "026084a0-3732-4e26-bb1b-be067aa60627"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding metadata with 14 columns\n",
            "Replacing existing metadata with 14 columns\n",
            "388 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "0 projection items activated\n",
            "Loading data for 388 events and 1025 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "channels = ['FP1', 'F3', 'F7', 'FC3', 'C3', 'C5', 'P3', 'P7', 'P9', 'PO7',\n",
        "            'PO3', 'O1', 'Oz', 'Pz', 'CPz', 'FP2', 'Fz', 'F4', 'F8', 'FC4',\n",
        "            'FCz', 'Cz', 'C4', 'C6', 'P4', 'P8', 'P10', 'PO8', 'PO4', 'O2']"
      ],
      "metadata": {
        "id": "KbgD__FpAl-_"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "channels3 = ['F3', 'F7', 'C3', 'P3', 'P7', 'O1', 'Oz', 'Pz', 'Fz', 'F4', 'F8', \n",
        "             'Cz', 'C4', 'P4', 'P8', 'O2']"
      ],
      "metadata": {
        "id": "MJKZTFuVuOGI"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs.pick_channels(channels3)\n",
        "X = epochs.get_data()"
      ],
      "metadata": {
        "id": "lXAqvoDwAjiV"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = (epochs.metadata.response_correct*1).to_numpy()\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zn72rasXAvIO",
        "outputId": "17698673-72fe-40e0-bdc0-191762e251a5"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
              "       0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
              "       1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0,\n",
              "       1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
              "       1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
              "       0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
              "       1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1,\n",
              "       1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
      ],
      "metadata": {
        "id": "-q-zfqpEA6zZ"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBjIE6YJBQQL",
        "outputId": "1e479093-5f5b-421c-d494-7f83bc730b9e"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(232, 16, 1025)"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kernels, chans, samples = 1, X_train.shape[1], X_train.shape[-1]"
      ],
      "metadata": {
        "id": "QAm53iq1BT0p"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train      = X_train.reshape(X_train.shape[0], chans, samples, kernels)\n",
        "X_val        = X_val.reshape(X_val.shape[0], chans, samples, kernels)\n",
        "X_test       = X_test.reshape(X_test.shape[0], chans, samples, kernels)"
      ],
      "metadata": {
        "id": "YsJZQrSeBN9O"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train      = np_utils.to_categorical(y_train)\n",
        "y_val        = np_utils.to_categorical(y_val)\n",
        "y_test       = np_utils.to_categorical(y_test)"
      ],
      "metadata": {
        "id": "dl_tExlpHVsu"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "HO-5Z7aWy0TD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def EEGNet(nb_classes, Chans = 64, Samples = 128, \n",
        "             dropoutRate = 0.5, kernLength = 64, F1 = 8, \n",
        "             D = 2, F2 = 16, norm_rate = 0.25, dropoutType = Dropout):\n",
        "    \n",
        "    input1   = Input(shape = (Chans, Samples, 1))\n",
        "\n",
        "    ##################################################################\n",
        "    block1       = Conv2D(F1, (1, kernLength), padding = 'same',\n",
        "                                   input_shape = (Chans, Samples, 1),\n",
        "                                   use_bias = False)(input1)\n",
        "    block1       = BatchNormalization()(block1)\n",
        "    block1       = DepthwiseConv2D((Chans, 1), use_bias = False, \n",
        "                                   depth_multiplier = D,\n",
        "                                   depthwise_constraint = max_norm(1.))(block1)\n",
        "    block1       = BatchNormalization()(block1)\n",
        "    block1       = Activation('elu')(block1)\n",
        "    block1       = AveragePooling2D((1, 4))(block1)\n",
        "    block1       = dropoutType(dropoutRate)(block1)\n",
        "    \n",
        "    block2       = SeparableConv2D(F2, (1, 16),\n",
        "                                   use_bias = False, padding = 'same')(block1)\n",
        "    block2       = BatchNormalization()(block2)\n",
        "    block2       = Activation('elu')(block2)\n",
        "    block2       = AveragePooling2D((1, 8))(block2)\n",
        "    block2       = dropoutType(dropoutRate)(block2)\n",
        "        \n",
        "    flatten      = Flatten(name = 'flatten')(block2)\n",
        "    \n",
        "    dense        = Dense(nb_classes, name = 'dense', \n",
        "                         kernel_constraint = max_norm(norm_rate))(flatten)\n",
        "    softmax      = Activation('softmax', name = 'softmax')(dense)\n",
        "    \n",
        "    return Model(inputs=input1, outputs=softmax)"
      ],
      "metadata": {
        "id": "I0CJ6V3Xy2Nt"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "XPUbfj6ty2rM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = EEGNet(nb_classes=2, Chans = chans, Samples = samples,dropoutRate = 0.5, \n",
        "               kernLength = 32, F1 = 8, D = 2, F2 = 16)\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='./tmp/checkpoint.h5', verbose=1,\n",
        "                               save_best_only=True)\n",
        "\n",
        "class_weights = {0:1, 1:1}\n",
        "fittedModel = model.fit(X_train, y_train, \n",
        "#                         batch_size = 128, \n",
        "                        epochs = 200, \n",
        "                        verbose = 2,\n",
        "                        validation_data=(X_val, y_val),\n",
        "                        callbacks=[checkpointer],\n",
        "                        class_weight = class_weights)"
      ],
      "metadata": {
        "id": "BOFqF7qXy8nt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "107deeb8-776b-4f90-ade1-2e63732e629d"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.69056, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 4s - loss: 0.6931 - accuracy: 0.5776 - val_loss: 0.6906 - val_accuracy: 0.7288 - 4s/epoch - 493ms/step\n",
            "Epoch 2/200\n",
            "\n",
            "Epoch 2: val_loss improved from 0.69056 to 0.68730, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 3s - loss: 0.6891 - accuracy: 0.6207 - val_loss: 0.6873 - val_accuracy: 0.7288 - 3s/epoch - 314ms/step\n",
            "Epoch 3/200\n",
            "\n",
            "Epoch 3: val_loss improved from 0.68730 to 0.68387, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 3s - loss: 0.6847 - accuracy: 0.6336 - val_loss: 0.6839 - val_accuracy: 0.7288 - 3s/epoch - 318ms/step\n",
            "Epoch 4/200\n",
            "\n",
            "Epoch 4: val_loss improved from 0.68387 to 0.67843, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 3s - loss: 0.6761 - accuracy: 0.6509 - val_loss: 0.6784 - val_accuracy: 0.7288 - 3s/epoch - 325ms/step\n",
            "Epoch 5/200\n",
            "\n",
            "Epoch 5: val_loss improved from 0.67843 to 0.67388, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 3s - loss: 0.6668 - accuracy: 0.6940 - val_loss: 0.6739 - val_accuracy: 0.7288 - 3s/epoch - 314ms/step\n",
            "Epoch 6/200\n",
            "\n",
            "Epoch 6: val_loss improved from 0.67388 to 0.67160, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 2s - loss: 0.6476 - accuracy: 0.7155 - val_loss: 0.6716 - val_accuracy: 0.7288 - 2s/epoch - 310ms/step\n",
            "Epoch 7/200\n",
            "\n",
            "Epoch 7: val_loss improved from 0.67160 to 0.66558, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 2s - loss: 0.6244 - accuracy: 0.7241 - val_loss: 0.6656 - val_accuracy: 0.7288 - 2s/epoch - 312ms/step\n",
            "Epoch 8/200\n",
            "\n",
            "Epoch 8: val_loss improved from 0.66558 to 0.65798, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 3s - loss: 0.6135 - accuracy: 0.7198 - val_loss: 0.6580 - val_accuracy: 0.7288 - 3s/epoch - 318ms/step\n",
            "Epoch 9/200\n",
            "\n",
            "Epoch 9: val_loss improved from 0.65798 to 0.65430, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 3s - loss: 0.5984 - accuracy: 0.7328 - val_loss: 0.6543 - val_accuracy: 0.7288 - 3s/epoch - 313ms/step\n",
            "Epoch 10/200\n",
            "\n",
            "Epoch 10: val_loss improved from 0.65430 to 0.65106, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 3s - loss: 0.5974 - accuracy: 0.7198 - val_loss: 0.6511 - val_accuracy: 0.7288 - 3s/epoch - 318ms/step\n",
            "Epoch 11/200\n",
            "\n",
            "Epoch 11: val_loss improved from 0.65106 to 0.65074, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 3s - loss: 0.5834 - accuracy: 0.7155 - val_loss: 0.6507 - val_accuracy: 0.7288 - 3s/epoch - 315ms/step\n",
            "Epoch 12/200\n",
            "\n",
            "Epoch 12: val_loss improved from 0.65074 to 0.64643, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 3s - loss: 0.5733 - accuracy: 0.6940 - val_loss: 0.6464 - val_accuracy: 0.7288 - 3s/epoch - 315ms/step\n",
            "Epoch 13/200\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.64643\n",
            "8/8 - 2s - loss: 0.5780 - accuracy: 0.7155 - val_loss: 0.6464 - val_accuracy: 0.7288 - 2s/epoch - 308ms/step\n",
            "Epoch 14/200\n",
            "\n",
            "Epoch 14: val_loss improved from 0.64643 to 0.64403, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 2s - loss: 0.5605 - accuracy: 0.7414 - val_loss: 0.6440 - val_accuracy: 0.7288 - 2s/epoch - 311ms/step\n",
            "Epoch 15/200\n",
            "\n",
            "Epoch 15: val_loss improved from 0.64403 to 0.63932, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 2s - loss: 0.5634 - accuracy: 0.7457 - val_loss: 0.6393 - val_accuracy: 0.7288 - 2s/epoch - 312ms/step\n",
            "Epoch 16/200\n",
            "\n",
            "Epoch 16: val_loss improved from 0.63932 to 0.63640, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 3s - loss: 0.5538 - accuracy: 0.7457 - val_loss: 0.6364 - val_accuracy: 0.7288 - 3s/epoch - 313ms/step\n",
            "Epoch 17/200\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.63640\n",
            "8/8 - 2s - loss: 0.5393 - accuracy: 0.7586 - val_loss: 0.6374 - val_accuracy: 0.7288 - 2s/epoch - 308ms/step\n",
            "Epoch 18/200\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.63640\n",
            "8/8 - 2s - loss: 0.5438 - accuracy: 0.7414 - val_loss: 0.6382 - val_accuracy: 0.7288 - 2s/epoch - 309ms/step\n",
            "Epoch 19/200\n",
            "\n",
            "Epoch 19: val_loss improved from 0.63640 to 0.63600, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 3s - loss: 0.5422 - accuracy: 0.7328 - val_loss: 0.6360 - val_accuracy: 0.7288 - 3s/epoch - 321ms/step\n",
            "Epoch 20/200\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.63600\n",
            "8/8 - 2s - loss: 0.5380 - accuracy: 0.7629 - val_loss: 0.6360 - val_accuracy: 0.7288 - 2s/epoch - 312ms/step\n",
            "Epoch 21/200\n",
            "\n",
            "Epoch 21: val_loss improved from 0.63600 to 0.63371, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 3s - loss: 0.5104 - accuracy: 0.7543 - val_loss: 0.6337 - val_accuracy: 0.7288 - 3s/epoch - 316ms/step\n",
            "Epoch 22/200\n",
            "\n",
            "Epoch 22: val_loss did not improve from 0.63371\n",
            "8/8 - 2s - loss: 0.5157 - accuracy: 0.7457 - val_loss: 0.6343 - val_accuracy: 0.7288 - 2s/epoch - 307ms/step\n",
            "Epoch 23/200\n",
            "\n",
            "Epoch 23: val_loss did not improve from 0.63371\n",
            "8/8 - 2s - loss: 0.5260 - accuracy: 0.7371 - val_loss: 0.6343 - val_accuracy: 0.7288 - 2s/epoch - 308ms/step\n",
            "Epoch 24/200\n",
            "\n",
            "Epoch 24: val_loss improved from 0.63371 to 0.63189, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 3s - loss: 0.5077 - accuracy: 0.7500 - val_loss: 0.6319 - val_accuracy: 0.7288 - 3s/epoch - 320ms/step\n",
            "Epoch 25/200\n",
            "\n",
            "Epoch 25: val_loss improved from 0.63189 to 0.62821, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 3s - loss: 0.5005 - accuracy: 0.7845 - val_loss: 0.6282 - val_accuracy: 0.7288 - 3s/epoch - 319ms/step\n",
            "Epoch 26/200\n",
            "\n",
            "Epoch 26: val_loss improved from 0.62821 to 0.62549, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 3s - loss: 0.5008 - accuracy: 0.7629 - val_loss: 0.6255 - val_accuracy: 0.7288 - 3s/epoch - 317ms/step\n",
            "Epoch 27/200\n",
            "\n",
            "Epoch 27: val_loss improved from 0.62549 to 0.61970, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 3s - loss: 0.4904 - accuracy: 0.7931 - val_loss: 0.6197 - val_accuracy: 0.7288 - 3s/epoch - 319ms/step\n",
            "Epoch 28/200\n",
            "\n",
            "Epoch 28: val_loss did not improve from 0.61970\n",
            "8/8 - 2s - loss: 0.4860 - accuracy: 0.8017 - val_loss: 0.6198 - val_accuracy: 0.7288 - 2s/epoch - 310ms/step\n",
            "Epoch 29/200\n",
            "\n",
            "Epoch 29: val_loss did not improve from 0.61970\n",
            "8/8 - 2s - loss: 0.4799 - accuracy: 0.7845 - val_loss: 0.6219 - val_accuracy: 0.7288 - 2s/epoch - 308ms/step\n",
            "Epoch 30/200\n",
            "\n",
            "Epoch 30: val_loss improved from 0.61970 to 0.61946, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 3s - loss: 0.4943 - accuracy: 0.7759 - val_loss: 0.6195 - val_accuracy: 0.7288 - 3s/epoch - 313ms/step\n",
            "Epoch 31/200\n",
            "\n",
            "Epoch 31: val_loss improved from 0.61946 to 0.61648, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 2s - loss: 0.4731 - accuracy: 0.8017 - val_loss: 0.6165 - val_accuracy: 0.7288 - 2s/epoch - 312ms/step\n",
            "Epoch 32/200\n",
            "\n",
            "Epoch 32: val_loss improved from 0.61648 to 0.61623, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 3s - loss: 0.4769 - accuracy: 0.7974 - val_loss: 0.6162 - val_accuracy: 0.7288 - 3s/epoch - 316ms/step\n",
            "Epoch 33/200\n",
            "\n",
            "Epoch 33: val_loss improved from 0.61623 to 0.61168, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 3s - loss: 0.4684 - accuracy: 0.8017 - val_loss: 0.6117 - val_accuracy: 0.7288 - 3s/epoch - 315ms/step\n",
            "Epoch 34/200\n",
            "\n",
            "Epoch 34: val_loss improved from 0.61168 to 0.60864, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 3s - loss: 0.4710 - accuracy: 0.8017 - val_loss: 0.6086 - val_accuracy: 0.7288 - 3s/epoch - 319ms/step\n",
            "Epoch 35/200\n",
            "\n",
            "Epoch 35: val_loss improved from 0.60864 to 0.60518, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 3s - loss: 0.4836 - accuracy: 0.7716 - val_loss: 0.6052 - val_accuracy: 0.7288 - 3s/epoch - 315ms/step\n",
            "Epoch 36/200\n",
            "\n",
            "Epoch 36: val_loss improved from 0.60518 to 0.59836, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 3s - loss: 0.4692 - accuracy: 0.8017 - val_loss: 0.5984 - val_accuracy: 0.7288 - 3s/epoch - 315ms/step\n",
            "Epoch 37/200\n",
            "\n",
            "Epoch 37: val_loss did not improve from 0.59836\n",
            "8/8 - 2s - loss: 0.4507 - accuracy: 0.8147 - val_loss: 0.6016 - val_accuracy: 0.7288 - 2s/epoch - 309ms/step\n",
            "Epoch 38/200\n",
            "\n",
            "Epoch 38: val_loss did not improve from 0.59836\n",
            "8/8 - 2s - loss: 0.4583 - accuracy: 0.7974 - val_loss: 0.6021 - val_accuracy: 0.7288 - 2s/epoch - 305ms/step\n",
            "Epoch 39/200\n",
            "\n",
            "Epoch 39: val_loss did not improve from 0.59836\n",
            "8/8 - 2s - loss: 0.4685 - accuracy: 0.7888 - val_loss: 0.6106 - val_accuracy: 0.7288 - 2s/epoch - 307ms/step\n",
            "Epoch 40/200\n",
            "\n",
            "Epoch 40: val_loss did not improve from 0.59836\n",
            "8/8 - 2s - loss: 0.4462 - accuracy: 0.8233 - val_loss: 0.6200 - val_accuracy: 0.7288 - 2s/epoch - 308ms/step\n",
            "Epoch 41/200\n",
            "\n",
            "Epoch 41: val_loss did not improve from 0.59836\n",
            "8/8 - 2s - loss: 0.4627 - accuracy: 0.8060 - val_loss: 0.6232 - val_accuracy: 0.7288 - 2s/epoch - 310ms/step\n",
            "Epoch 42/200\n",
            "\n",
            "Epoch 42: val_loss did not improve from 0.59836\n",
            "8/8 - 2s - loss: 0.4415 - accuracy: 0.8319 - val_loss: 0.6414 - val_accuracy: 0.7288 - 2s/epoch - 310ms/step\n",
            "Epoch 43/200\n",
            "\n",
            "Epoch 43: val_loss did not improve from 0.59836\n",
            "8/8 - 2s - loss: 0.4322 - accuracy: 0.8017 - val_loss: 0.6688 - val_accuracy: 0.7288 - 2s/epoch - 311ms/step\n",
            "Epoch 44/200\n",
            "\n",
            "Epoch 44: val_loss did not improve from 0.59836\n",
            "8/8 - 2s - loss: 0.4486 - accuracy: 0.8190 - val_loss: 0.7107 - val_accuracy: 0.2712 - 2s/epoch - 312ms/step\n",
            "Epoch 45/200\n",
            "\n",
            "Epoch 45: val_loss did not improve from 0.59836\n",
            "8/8 - 2s - loss: 0.4481 - accuracy: 0.8147 - val_loss: 0.7483 - val_accuracy: 0.2712 - 2s/epoch - 312ms/step\n",
            "Epoch 46/200\n",
            "\n",
            "Epoch 46: val_loss did not improve from 0.59836\n",
            "8/8 - 2s - loss: 0.4481 - accuracy: 0.8147 - val_loss: 0.7517 - val_accuracy: 0.2712 - 2s/epoch - 311ms/step\n",
            "Epoch 47/200\n",
            "\n",
            "Epoch 47: val_loss did not improve from 0.59836\n",
            "8/8 - 2s - loss: 0.4472 - accuracy: 0.8190 - val_loss: 0.7011 - val_accuracy: 0.2881 - 2s/epoch - 312ms/step\n",
            "Epoch 48/200\n",
            "\n",
            "Epoch 48: val_loss did not improve from 0.59836\n",
            "8/8 - 2s - loss: 0.4333 - accuracy: 0.8319 - val_loss: 0.6635 - val_accuracy: 0.7288 - 2s/epoch - 306ms/step\n",
            "Epoch 49/200\n",
            "\n",
            "Epoch 49: val_loss did not improve from 0.59836\n",
            "8/8 - 2s - loss: 0.4392 - accuracy: 0.8276 - val_loss: 0.6449 - val_accuracy: 0.7288 - 2s/epoch - 309ms/step\n",
            "Epoch 50/200\n",
            "\n",
            "Epoch 50: val_loss did not improve from 0.59836\n",
            "8/8 - 2s - loss: 0.4378 - accuracy: 0.8276 - val_loss: 0.6141 - val_accuracy: 0.7288 - 2s/epoch - 310ms/step\n",
            "Epoch 51/200\n",
            "\n",
            "Epoch 51: val_loss did not improve from 0.59836\n",
            "8/8 - 2s - loss: 0.4343 - accuracy: 0.8017 - val_loss: 0.6266 - val_accuracy: 0.7288 - 2s/epoch - 312ms/step\n",
            "Epoch 52/200\n",
            "\n",
            "Epoch 52: val_loss did not improve from 0.59836\n",
            "8/8 - 2s - loss: 0.4290 - accuracy: 0.8405 - val_loss: 0.6656 - val_accuracy: 0.8305 - 2s/epoch - 309ms/step\n",
            "Epoch 53/200\n",
            "\n",
            "Epoch 53: val_loss did not improve from 0.59836\n",
            "8/8 - 2s - loss: 0.4233 - accuracy: 0.8103 - val_loss: 0.7366 - val_accuracy: 0.2712 - 2s/epoch - 310ms/step\n",
            "Epoch 54/200\n",
            "\n",
            "Epoch 54: val_loss did not improve from 0.59836\n",
            "8/8 - 2s - loss: 0.4181 - accuracy: 0.8448 - val_loss: 0.7727 - val_accuracy: 0.2712 - 2s/epoch - 311ms/step\n",
            "Epoch 55/200\n",
            "\n",
            "Epoch 55: val_loss did not improve from 0.59836\n",
            "8/8 - 2s - loss: 0.4194 - accuracy: 0.8233 - val_loss: 0.8355 - val_accuracy: 0.2712 - 2s/epoch - 308ms/step\n",
            "Epoch 56/200\n",
            "\n",
            "Epoch 56: val_loss did not improve from 0.59836\n",
            "8/8 - 2s - loss: 0.4185 - accuracy: 0.8233 - val_loss: 0.8983 - val_accuracy: 0.2712 - 2s/epoch - 308ms/step\n",
            "Epoch 57/200\n",
            "\n",
            "Epoch 57: val_loss did not improve from 0.59836\n",
            "8/8 - 2s - loss: 0.4192 - accuracy: 0.8319 - val_loss: 0.9131 - val_accuracy: 0.2712 - 2s/epoch - 307ms/step\n",
            "Epoch 58/200\n",
            "\n",
            "Epoch 58: val_loss did not improve from 0.59836\n",
            "8/8 - 2s - loss: 0.4240 - accuracy: 0.8103 - val_loss: 0.8465 - val_accuracy: 0.2712 - 2s/epoch - 308ms/step\n",
            "Epoch 59/200\n",
            "\n",
            "Epoch 59: val_loss did not improve from 0.59836\n",
            "8/8 - 2s - loss: 0.4443 - accuracy: 0.7974 - val_loss: 0.7895 - val_accuracy: 0.2712 - 2s/epoch - 311ms/step\n",
            "Epoch 60/200\n",
            "\n",
            "Epoch 60: val_loss did not improve from 0.59836\n",
            "8/8 - 2s - loss: 0.4194 - accuracy: 0.8233 - val_loss: 0.6287 - val_accuracy: 0.8305 - 2s/epoch - 308ms/step\n",
            "Epoch 61/200\n",
            "\n",
            "Epoch 61: val_loss improved from 0.59836 to 0.57081, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 3s - loss: 0.4135 - accuracy: 0.8319 - val_loss: 0.5708 - val_accuracy: 0.7288 - 3s/epoch - 318ms/step\n",
            "Epoch 62/200\n",
            "\n",
            "Epoch 62: val_loss improved from 0.57081 to 0.55794, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 3s - loss: 0.4085 - accuracy: 0.8448 - val_loss: 0.5579 - val_accuracy: 0.7288 - 3s/epoch - 313ms/step\n",
            "Epoch 63/200\n",
            "\n",
            "Epoch 63: val_loss improved from 0.55794 to 0.55242, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 3s - loss: 0.4087 - accuracy: 0.8362 - val_loss: 0.5524 - val_accuracy: 0.7288 - 3s/epoch - 318ms/step\n",
            "Epoch 64/200\n",
            "\n",
            "Epoch 64: val_loss improved from 0.55242 to 0.54915, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 3s - loss: 0.4091 - accuracy: 0.8060 - val_loss: 0.5491 - val_accuracy: 0.7288 - 3s/epoch - 314ms/step\n",
            "Epoch 65/200\n",
            "\n",
            "Epoch 65: val_loss improved from 0.54915 to 0.54480, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 3s - loss: 0.4080 - accuracy: 0.8362 - val_loss: 0.5448 - val_accuracy: 0.7288 - 3s/epoch - 321ms/step\n",
            "Epoch 66/200\n",
            "\n",
            "Epoch 66: val_loss improved from 0.54480 to 0.53765, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 3s - loss: 0.4050 - accuracy: 0.8147 - val_loss: 0.5376 - val_accuracy: 0.7288 - 3s/epoch - 315ms/step\n",
            "Epoch 67/200\n",
            "\n",
            "Epoch 67: val_loss improved from 0.53765 to 0.53356, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 3s - loss: 0.3967 - accuracy: 0.8491 - val_loss: 0.5336 - val_accuracy: 0.7288 - 3s/epoch - 328ms/step\n",
            "Epoch 68/200\n",
            "\n",
            "Epoch 68: val_loss did not improve from 0.53356\n",
            "8/8 - 2s - loss: 0.3995 - accuracy: 0.8405 - val_loss: 0.5487 - val_accuracy: 0.7288 - 2s/epoch - 307ms/step\n",
            "Epoch 69/200\n",
            "\n",
            "Epoch 69: val_loss did not improve from 0.53356\n",
            "8/8 - 2s - loss: 0.4026 - accuracy: 0.8319 - val_loss: 0.5368 - val_accuracy: 0.7288 - 2s/epoch - 310ms/step\n",
            "Epoch 70/200\n",
            "\n",
            "Epoch 70: val_loss did not improve from 0.53356\n",
            "8/8 - 2s - loss: 0.4025 - accuracy: 0.8233 - val_loss: 0.5366 - val_accuracy: 0.7288 - 2s/epoch - 310ms/step\n",
            "Epoch 71/200\n",
            "\n",
            "Epoch 71: val_loss did not improve from 0.53356\n",
            "8/8 - 3s - loss: 0.4041 - accuracy: 0.8319 - val_loss: 0.5479 - val_accuracy: 0.7288 - 3s/epoch - 315ms/step\n",
            "Epoch 72/200\n",
            "\n",
            "Epoch 72: val_loss did not improve from 0.53356\n",
            "8/8 - 2s - loss: 0.4044 - accuracy: 0.8276 - val_loss: 0.5560 - val_accuracy: 0.7288 - 2s/epoch - 312ms/step\n",
            "Epoch 73/200\n",
            "\n",
            "Epoch 73: val_loss improved from 0.53356 to 0.51204, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 3s - loss: 0.4109 - accuracy: 0.8319 - val_loss: 0.5120 - val_accuracy: 0.7288 - 3s/epoch - 317ms/step\n",
            "Epoch 74/200\n",
            "\n",
            "Epoch 74: val_loss did not improve from 0.51204\n",
            "8/8 - 2s - loss: 0.3960 - accuracy: 0.8405 - val_loss: 0.5284 - val_accuracy: 0.7288 - 2s/epoch - 309ms/step\n",
            "Epoch 75/200\n",
            "\n",
            "Epoch 75: val_loss did not improve from 0.51204\n",
            "8/8 - 3s - loss: 0.4042 - accuracy: 0.8448 - val_loss: 0.5514 - val_accuracy: 0.7288 - 3s/epoch - 313ms/step\n",
            "Epoch 76/200\n",
            "\n",
            "Epoch 76: val_loss did not improve from 0.51204\n",
            "8/8 - 2s - loss: 0.4069 - accuracy: 0.8276 - val_loss: 0.5622 - val_accuracy: 0.7288 - 2s/epoch - 312ms/step\n",
            "Epoch 77/200\n",
            "\n",
            "Epoch 77: val_loss did not improve from 0.51204\n",
            "8/8 - 2s - loss: 0.4029 - accuracy: 0.8491 - val_loss: 0.5406 - val_accuracy: 0.7288 - 2s/epoch - 308ms/step\n",
            "Epoch 78/200\n",
            "\n",
            "Epoch 78: val_loss improved from 0.51204 to 0.51074, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 3s - loss: 0.4033 - accuracy: 0.8362 - val_loss: 0.5107 - val_accuracy: 0.7288 - 3s/epoch - 315ms/step\n",
            "Epoch 79/200\n",
            "\n",
            "Epoch 79: val_loss did not improve from 0.51074\n",
            "8/8 - 2s - loss: 0.4123 - accuracy: 0.8276 - val_loss: 0.5123 - val_accuracy: 0.7288 - 2s/epoch - 312ms/step\n",
            "Epoch 80/200\n",
            "\n",
            "Epoch 80: val_loss did not improve from 0.51074\n",
            "8/8 - 2s - loss: 0.3950 - accuracy: 0.8405 - val_loss: 0.5120 - val_accuracy: 0.7288 - 2s/epoch - 311ms/step\n",
            "Epoch 81/200\n",
            "\n",
            "Epoch 81: val_loss did not improve from 0.51074\n",
            "8/8 - 2s - loss: 0.3969 - accuracy: 0.8233 - val_loss: 0.5119 - val_accuracy: 0.7288 - 2s/epoch - 309ms/step\n",
            "Epoch 82/200\n",
            "\n",
            "Epoch 82: val_loss improved from 0.51074 to 0.50987, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 3s - loss: 0.3922 - accuracy: 0.8362 - val_loss: 0.5099 - val_accuracy: 0.7288 - 3s/epoch - 313ms/step\n",
            "Epoch 83/200\n",
            "\n",
            "Epoch 83: val_loss did not improve from 0.50987\n",
            "8/8 - 2s - loss: 0.3785 - accuracy: 0.8664 - val_loss: 0.5128 - val_accuracy: 0.7288 - 2s/epoch - 311ms/step\n",
            "Epoch 84/200\n",
            "\n",
            "Epoch 84: val_loss improved from 0.50987 to 0.49754, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 3s - loss: 0.3905 - accuracy: 0.8578 - val_loss: 0.4975 - val_accuracy: 0.7288 - 3s/epoch - 315ms/step\n",
            "Epoch 85/200\n",
            "\n",
            "Epoch 85: val_loss did not improve from 0.49754\n",
            "8/8 - 2s - loss: 0.3865 - accuracy: 0.8405 - val_loss: 0.5266 - val_accuracy: 0.7288 - 2s/epoch - 311ms/step\n",
            "Epoch 86/200\n",
            "\n",
            "Epoch 86: val_loss did not improve from 0.49754\n",
            "8/8 - 2s - loss: 0.3941 - accuracy: 0.8448 - val_loss: 0.5412 - val_accuracy: 0.7288 - 2s/epoch - 308ms/step\n",
            "Epoch 87/200\n",
            "\n",
            "Epoch 87: val_loss did not improve from 0.49754\n",
            "8/8 - 2s - loss: 0.3799 - accuracy: 0.8405 - val_loss: 0.5769 - val_accuracy: 0.7288 - 2s/epoch - 311ms/step\n",
            "Epoch 88/200\n",
            "\n",
            "Epoch 88: val_loss did not improve from 0.49754\n",
            "8/8 - 2s - loss: 0.3900 - accuracy: 0.8578 - val_loss: 0.5994 - val_accuracy: 0.7288 - 2s/epoch - 311ms/step\n",
            "Epoch 89/200\n",
            "\n",
            "Epoch 89: val_loss did not improve from 0.49754\n",
            "8/8 - 2s - loss: 0.3958 - accuracy: 0.8276 - val_loss: 0.5622 - val_accuracy: 0.7288 - 2s/epoch - 309ms/step\n",
            "Epoch 90/200\n",
            "\n",
            "Epoch 90: val_loss did not improve from 0.49754\n",
            "8/8 - 2s - loss: 0.3902 - accuracy: 0.8491 - val_loss: 0.6476 - val_accuracy: 0.7288 - 2s/epoch - 308ms/step\n",
            "Epoch 91/200\n",
            "\n",
            "Epoch 91: val_loss did not improve from 0.49754\n",
            "8/8 - 2s - loss: 0.4044 - accuracy: 0.8362 - val_loss: 0.5060 - val_accuracy: 0.7288 - 2s/epoch - 310ms/step\n",
            "Epoch 92/200\n",
            "\n",
            "Epoch 92: val_loss improved from 0.49754 to 0.43970, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 3s - loss: 0.3813 - accuracy: 0.8362 - val_loss: 0.4397 - val_accuracy: 0.7627 - 3s/epoch - 319ms/step\n",
            "Epoch 93/200\n",
            "\n",
            "Epoch 93: val_loss improved from 0.43970 to 0.43763, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 2s - loss: 0.3842 - accuracy: 0.8190 - val_loss: 0.4376 - val_accuracy: 0.7797 - 2s/epoch - 311ms/step\n",
            "Epoch 94/200\n",
            "\n",
            "Epoch 94: val_loss did not improve from 0.43763\n",
            "8/8 - 2s - loss: 0.3866 - accuracy: 0.8405 - val_loss: 0.4776 - val_accuracy: 0.7288 - 2s/epoch - 310ms/step\n",
            "Epoch 95/200\n",
            "\n",
            "Epoch 95: val_loss improved from 0.43763 to 0.42953, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 3s - loss: 0.3748 - accuracy: 0.8448 - val_loss: 0.4295 - val_accuracy: 0.7627 - 3s/epoch - 317ms/step\n",
            "Epoch 96/200\n",
            "\n",
            "Epoch 96: val_loss did not improve from 0.42953\n",
            "8/8 - 2s - loss: 0.3821 - accuracy: 0.8491 - val_loss: 0.4804 - val_accuracy: 0.7288 - 2s/epoch - 311ms/step\n",
            "Epoch 97/200\n",
            "\n",
            "Epoch 97: val_loss did not improve from 0.42953\n",
            "8/8 - 2s - loss: 0.3829 - accuracy: 0.8448 - val_loss: 0.6627 - val_accuracy: 0.7288 - 2s/epoch - 310ms/step\n",
            "Epoch 98/200\n",
            "\n",
            "Epoch 98: val_loss did not improve from 0.42953\n",
            "8/8 - 2s - loss: 0.3922 - accuracy: 0.8362 - val_loss: 0.7110 - val_accuracy: 0.7288 - 2s/epoch - 306ms/step\n",
            "Epoch 99/200\n",
            "\n",
            "Epoch 99: val_loss did not improve from 0.42953\n",
            "8/8 - 2s - loss: 0.3918 - accuracy: 0.8276 - val_loss: 0.9025 - val_accuracy: 0.7288 - 2s/epoch - 309ms/step\n",
            "Epoch 100/200\n",
            "\n",
            "Epoch 100: val_loss did not improve from 0.42953\n",
            "8/8 - 2s - loss: 0.3846 - accuracy: 0.8362 - val_loss: 0.7054 - val_accuracy: 0.7288 - 2s/epoch - 311ms/step\n",
            "Epoch 101/200\n",
            "\n",
            "Epoch 101: val_loss did not improve from 0.42953\n",
            "8/8 - 2s - loss: 0.3867 - accuracy: 0.8405 - val_loss: 0.5653 - val_accuracy: 0.7288 - 2s/epoch - 308ms/step\n",
            "Epoch 102/200\n",
            "\n",
            "Epoch 102: val_loss did not improve from 0.42953\n",
            "8/8 - 2s - loss: 0.3903 - accuracy: 0.8491 - val_loss: 0.4549 - val_accuracy: 0.7288 - 2s/epoch - 309ms/step\n",
            "Epoch 103/200\n",
            "\n",
            "Epoch 103: val_loss did not improve from 0.42953\n",
            "8/8 - 2s - loss: 0.3700 - accuracy: 0.8578 - val_loss: 0.4443 - val_accuracy: 0.7627 - 2s/epoch - 308ms/step\n",
            "Epoch 104/200\n",
            "\n",
            "Epoch 104: val_loss improved from 0.42953 to 0.42824, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 3s - loss: 0.4001 - accuracy: 0.8491 - val_loss: 0.4282 - val_accuracy: 0.7966 - 3s/epoch - 321ms/step\n",
            "Epoch 105/200\n",
            "\n",
            "Epoch 105: val_loss did not improve from 0.42824\n",
            "8/8 - 2s - loss: 0.3823 - accuracy: 0.8491 - val_loss: 0.4313 - val_accuracy: 0.8814 - 2s/epoch - 311ms/step\n",
            "Epoch 106/200\n",
            "\n",
            "Epoch 106: val_loss did not improve from 0.42824\n",
            "8/8 - 2s - loss: 0.3699 - accuracy: 0.8448 - val_loss: 0.4835 - val_accuracy: 0.7966 - 2s/epoch - 311ms/step\n",
            "Epoch 107/200\n",
            "\n",
            "Epoch 107: val_loss did not improve from 0.42824\n",
            "8/8 - 2s - loss: 0.3945 - accuracy: 0.8319 - val_loss: 0.5180 - val_accuracy: 0.7458 - 2s/epoch - 306ms/step\n",
            "Epoch 108/200\n",
            "\n",
            "Epoch 108: val_loss did not improve from 0.42824\n",
            "8/8 - 2s - loss: 0.3770 - accuracy: 0.8362 - val_loss: 0.4655 - val_accuracy: 0.7966 - 2s/epoch - 311ms/step\n",
            "Epoch 109/200\n",
            "\n",
            "Epoch 109: val_loss did not improve from 0.42824\n",
            "8/8 - 2s - loss: 0.3776 - accuracy: 0.8578 - val_loss: 0.4285 - val_accuracy: 0.8475 - 2s/epoch - 308ms/step\n",
            "Epoch 110/200\n",
            "\n",
            "Epoch 110: val_loss did not improve from 0.42824\n",
            "8/8 - 2s - loss: 0.3841 - accuracy: 0.8578 - val_loss: 0.4324 - val_accuracy: 0.7627 - 2s/epoch - 305ms/step\n",
            "Epoch 111/200\n",
            "\n",
            "Epoch 111: val_loss did not improve from 0.42824\n",
            "8/8 - 2s - loss: 0.3877 - accuracy: 0.8362 - val_loss: 0.4398 - val_accuracy: 0.8475 - 2s/epoch - 310ms/step\n",
            "Epoch 112/200\n",
            "\n",
            "Epoch 112: val_loss did not improve from 0.42824\n",
            "8/8 - 2s - loss: 0.3883 - accuracy: 0.8448 - val_loss: 0.5076 - val_accuracy: 0.7797 - 2s/epoch - 312ms/step\n",
            "Epoch 113/200\n",
            "\n",
            "Epoch 113: val_loss did not improve from 0.42824\n",
            "8/8 - 3s - loss: 0.3790 - accuracy: 0.8534 - val_loss: 0.4907 - val_accuracy: 0.7797 - 3s/epoch - 316ms/step\n",
            "Epoch 114/200\n",
            "\n",
            "Epoch 114: val_loss did not improve from 0.42824\n",
            "8/8 - 3s - loss: 0.3632 - accuracy: 0.8664 - val_loss: 0.5190 - val_accuracy: 0.7966 - 3s/epoch - 313ms/step\n",
            "Epoch 115/200\n",
            "\n",
            "Epoch 115: val_loss did not improve from 0.42824\n",
            "8/8 - 3s - loss: 0.3846 - accuracy: 0.8319 - val_loss: 0.5356 - val_accuracy: 0.8305 - 3s/epoch - 330ms/step\n",
            "Epoch 116/200\n",
            "\n",
            "Epoch 116: val_loss did not improve from 0.42824\n",
            "8/8 - 3s - loss: 0.3801 - accuracy: 0.8491 - val_loss: 0.6078 - val_accuracy: 0.6441 - 3s/epoch - 316ms/step\n",
            "Epoch 117/200\n",
            "\n",
            "Epoch 117: val_loss did not improve from 0.42824\n",
            "8/8 - 2s - loss: 0.3748 - accuracy: 0.8405 - val_loss: 0.5909 - val_accuracy: 0.6610 - 2s/epoch - 310ms/step\n",
            "Epoch 118/200\n",
            "\n",
            "Epoch 118: val_loss did not improve from 0.42824\n",
            "8/8 - 3s - loss: 0.3837 - accuracy: 0.8448 - val_loss: 0.5683 - val_accuracy: 0.7288 - 3s/epoch - 318ms/step\n",
            "Epoch 119/200\n",
            "\n",
            "Epoch 119: val_loss did not improve from 0.42824\n",
            "8/8 - 2s - loss: 0.3642 - accuracy: 0.8707 - val_loss: 0.5738 - val_accuracy: 0.7119 - 2s/epoch - 311ms/step\n",
            "Epoch 120/200\n",
            "\n",
            "Epoch 120: val_loss did not improve from 0.42824\n",
            "8/8 - 3s - loss: 0.3710 - accuracy: 0.8534 - val_loss: 0.5416 - val_accuracy: 0.7627 - 3s/epoch - 315ms/step\n",
            "Epoch 121/200\n",
            "\n",
            "Epoch 121: val_loss did not improve from 0.42824\n",
            "8/8 - 3s - loss: 0.3868 - accuracy: 0.8362 - val_loss: 0.5094 - val_accuracy: 0.8644 - 3s/epoch - 317ms/step\n",
            "Epoch 122/200\n",
            "\n",
            "Epoch 122: val_loss did not improve from 0.42824\n",
            "8/8 - 3s - loss: 0.3716 - accuracy: 0.8534 - val_loss: 0.4418 - val_accuracy: 0.8644 - 3s/epoch - 314ms/step\n",
            "Epoch 123/200\n",
            "\n",
            "Epoch 123: val_loss improved from 0.42824 to 0.42449, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 3s - loss: 0.3725 - accuracy: 0.8362 - val_loss: 0.4245 - val_accuracy: 0.8644 - 3s/epoch - 321ms/step\n",
            "Epoch 124/200\n",
            "\n",
            "Epoch 124: val_loss did not improve from 0.42449\n",
            "8/8 - 3s - loss: 0.3738 - accuracy: 0.8621 - val_loss: 0.4391 - val_accuracy: 0.8644 - 3s/epoch - 317ms/step\n",
            "Epoch 125/200\n",
            "\n",
            "Epoch 125: val_loss improved from 0.42449 to 0.41382, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 3s - loss: 0.3789 - accuracy: 0.8448 - val_loss: 0.4138 - val_accuracy: 0.8475 - 3s/epoch - 314ms/step\n",
            "Epoch 126/200\n",
            "\n",
            "Epoch 126: val_loss did not improve from 0.41382\n",
            "8/8 - 2s - loss: 0.3785 - accuracy: 0.8578 - val_loss: 0.4544 - val_accuracy: 0.8475 - 2s/epoch - 307ms/step\n",
            "Epoch 127/200\n",
            "\n",
            "Epoch 127: val_loss did not improve from 0.41382\n",
            "8/8 - 2s - loss: 0.3739 - accuracy: 0.8319 - val_loss: 0.4290 - val_accuracy: 0.8305 - 2s/epoch - 310ms/step\n",
            "Epoch 128/200\n",
            "\n",
            "Epoch 128: val_loss did not improve from 0.41382\n",
            "8/8 - 2s - loss: 0.3722 - accuracy: 0.8621 - val_loss: 0.4254 - val_accuracy: 0.7966 - 2s/epoch - 309ms/step\n",
            "Epoch 129/200\n",
            "\n",
            "Epoch 129: val_loss did not improve from 0.41382\n",
            "8/8 - 2s - loss: 0.3697 - accuracy: 0.8491 - val_loss: 0.4867 - val_accuracy: 0.7966 - 2s/epoch - 310ms/step\n",
            "Epoch 130/200\n",
            "\n",
            "Epoch 130: val_loss did not improve from 0.41382\n",
            "8/8 - 2s - loss: 0.3626 - accuracy: 0.8233 - val_loss: 0.5161 - val_accuracy: 0.7627 - 2s/epoch - 309ms/step\n",
            "Epoch 131/200\n",
            "\n",
            "Epoch 131: val_loss did not improve from 0.41382\n",
            "8/8 - 2s - loss: 0.3582 - accuracy: 0.8534 - val_loss: 0.5553 - val_accuracy: 0.6780 - 2s/epoch - 311ms/step\n",
            "Epoch 132/200\n",
            "\n",
            "Epoch 132: val_loss did not improve from 0.41382\n",
            "8/8 - 2s - loss: 0.3655 - accuracy: 0.8276 - val_loss: 0.5367 - val_accuracy: 0.7288 - 2s/epoch - 306ms/step\n",
            "Epoch 133/200\n",
            "\n",
            "Epoch 133: val_loss did not improve from 0.41382\n",
            "8/8 - 2s - loss: 0.3724 - accuracy: 0.8491 - val_loss: 0.5093 - val_accuracy: 0.7966 - 2s/epoch - 309ms/step\n",
            "Epoch 134/200\n",
            "\n",
            "Epoch 134: val_loss did not improve from 0.41382\n",
            "8/8 - 2s - loss: 0.3776 - accuracy: 0.8448 - val_loss: 0.5300 - val_accuracy: 0.7797 - 2s/epoch - 306ms/step\n",
            "Epoch 135/200\n",
            "\n",
            "Epoch 135: val_loss did not improve from 0.41382\n",
            "8/8 - 2s - loss: 0.3445 - accuracy: 0.8405 - val_loss: 0.5279 - val_accuracy: 0.7797 - 2s/epoch - 307ms/step\n",
            "Epoch 136/200\n",
            "\n",
            "Epoch 136: val_loss did not improve from 0.41382\n",
            "8/8 - 2s - loss: 0.3723 - accuracy: 0.8448 - val_loss: 0.4641 - val_accuracy: 0.8644 - 2s/epoch - 310ms/step\n",
            "Epoch 137/200\n",
            "\n",
            "Epoch 137: val_loss improved from 0.41382 to 0.39824, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 3s - loss: 0.3655 - accuracy: 0.8621 - val_loss: 0.3982 - val_accuracy: 0.8475 - 3s/epoch - 314ms/step\n",
            "Epoch 138/200\n",
            "\n",
            "Epoch 138: val_loss improved from 0.39824 to 0.39654, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 2s - loss: 0.3663 - accuracy: 0.8491 - val_loss: 0.3965 - val_accuracy: 0.7797 - 2s/epoch - 312ms/step\n",
            "Epoch 139/200\n",
            "\n",
            "Epoch 139: val_loss did not improve from 0.39654\n",
            "8/8 - 2s - loss: 0.3614 - accuracy: 0.8578 - val_loss: 0.5784 - val_accuracy: 0.7288 - 2s/epoch - 309ms/step\n",
            "Epoch 140/200\n",
            "\n",
            "Epoch 140: val_loss did not improve from 0.39654\n",
            "8/8 - 2s - loss: 0.3634 - accuracy: 0.8534 - val_loss: 0.4306 - val_accuracy: 0.7797 - 2s/epoch - 309ms/step\n",
            "Epoch 141/200\n",
            "\n",
            "Epoch 141: val_loss improved from 0.39654 to 0.38255, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 3s - loss: 0.3668 - accuracy: 0.8621 - val_loss: 0.3826 - val_accuracy: 0.8136 - 3s/epoch - 315ms/step\n",
            "Epoch 142/200\n",
            "\n",
            "Epoch 142: val_loss improved from 0.38255 to 0.37293, saving model to ./tmp/checkpoint.h5\n",
            "8/8 - 2s - loss: 0.3516 - accuracy: 0.8319 - val_loss: 0.3729 - val_accuracy: 0.8305 - 2s/epoch - 311ms/step\n",
            "Epoch 143/200\n",
            "\n",
            "Epoch 143: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3556 - accuracy: 0.8707 - val_loss: 0.4299 - val_accuracy: 0.7797 - 2s/epoch - 309ms/step\n",
            "Epoch 144/200\n",
            "\n",
            "Epoch 144: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3631 - accuracy: 0.8534 - val_loss: 0.3833 - val_accuracy: 0.8136 - 2s/epoch - 309ms/step\n",
            "Epoch 145/200\n",
            "\n",
            "Epoch 145: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3585 - accuracy: 0.8534 - val_loss: 0.3815 - val_accuracy: 0.8136 - 2s/epoch - 306ms/step\n",
            "Epoch 146/200\n",
            "\n",
            "Epoch 146: val_loss did not improve from 0.37293\n",
            "8/8 - 3s - loss: 0.3444 - accuracy: 0.8664 - val_loss: 0.4780 - val_accuracy: 0.7458 - 3s/epoch - 313ms/step\n",
            "Epoch 147/200\n",
            "\n",
            "Epoch 147: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3513 - accuracy: 0.8578 - val_loss: 0.5052 - val_accuracy: 0.7458 - 2s/epoch - 307ms/step\n",
            "Epoch 148/200\n",
            "\n",
            "Epoch 148: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3686 - accuracy: 0.8362 - val_loss: 0.5552 - val_accuracy: 0.7288 - 2s/epoch - 309ms/step\n",
            "Epoch 149/200\n",
            "\n",
            "Epoch 149: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3409 - accuracy: 0.8707 - val_loss: 0.4870 - val_accuracy: 0.7458 - 2s/epoch - 311ms/step\n",
            "Epoch 150/200\n",
            "\n",
            "Epoch 150: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3526 - accuracy: 0.8534 - val_loss: 0.4070 - val_accuracy: 0.7966 - 2s/epoch - 307ms/step\n",
            "Epoch 151/200\n",
            "\n",
            "Epoch 151: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3536 - accuracy: 0.8534 - val_loss: 0.5216 - val_accuracy: 0.7288 - 2s/epoch - 307ms/step\n",
            "Epoch 152/200\n",
            "\n",
            "Epoch 152: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3413 - accuracy: 0.8750 - val_loss: 0.6191 - val_accuracy: 0.7288 - 2s/epoch - 309ms/step\n",
            "Epoch 153/200\n",
            "\n",
            "Epoch 153: val_loss did not improve from 0.37293\n",
            "8/8 - 3s - loss: 0.3670 - accuracy: 0.8491 - val_loss: 0.6860 - val_accuracy: 0.7288 - 3s/epoch - 313ms/step\n",
            "Epoch 154/200\n",
            "\n",
            "Epoch 154: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3512 - accuracy: 0.8621 - val_loss: 0.4611 - val_accuracy: 0.7458 - 2s/epoch - 308ms/step\n",
            "Epoch 155/200\n",
            "\n",
            "Epoch 155: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3404 - accuracy: 0.8793 - val_loss: 0.4567 - val_accuracy: 0.7458 - 2s/epoch - 309ms/step\n",
            "Epoch 156/200\n",
            "\n",
            "Epoch 156: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3582 - accuracy: 0.8534 - val_loss: 0.6449 - val_accuracy: 0.7288 - 2s/epoch - 308ms/step\n",
            "Epoch 157/200\n",
            "\n",
            "Epoch 157: val_loss did not improve from 0.37293\n",
            "8/8 - 3s - loss: 0.3651 - accuracy: 0.8190 - val_loss: 0.4827 - val_accuracy: 0.7458 - 3s/epoch - 313ms/step\n",
            "Epoch 158/200\n",
            "\n",
            "Epoch 158: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3539 - accuracy: 0.8621 - val_loss: 0.4442 - val_accuracy: 0.7627 - 2s/epoch - 308ms/step\n",
            "Epoch 159/200\n",
            "\n",
            "Epoch 159: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3612 - accuracy: 0.8664 - val_loss: 0.4693 - val_accuracy: 0.7458 - 2s/epoch - 306ms/step\n",
            "Epoch 160/200\n",
            "\n",
            "Epoch 160: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3487 - accuracy: 0.8621 - val_loss: 0.4127 - val_accuracy: 0.7627 - 2s/epoch - 308ms/step\n",
            "Epoch 161/200\n",
            "\n",
            "Epoch 161: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3415 - accuracy: 0.8922 - val_loss: 0.4874 - val_accuracy: 0.7458 - 2s/epoch - 311ms/step\n",
            "Epoch 162/200\n",
            "\n",
            "Epoch 162: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3536 - accuracy: 0.8491 - val_loss: 0.4654 - val_accuracy: 0.7458 - 2s/epoch - 307ms/step\n",
            "Epoch 163/200\n",
            "\n",
            "Epoch 163: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3478 - accuracy: 0.8578 - val_loss: 0.4329 - val_accuracy: 0.7966 - 2s/epoch - 310ms/step\n",
            "Epoch 164/200\n",
            "\n",
            "Epoch 164: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3491 - accuracy: 0.8707 - val_loss: 0.4350 - val_accuracy: 0.8136 - 2s/epoch - 310ms/step\n",
            "Epoch 165/200\n",
            "\n",
            "Epoch 165: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3637 - accuracy: 0.8276 - val_loss: 0.4579 - val_accuracy: 0.8305 - 2s/epoch - 307ms/step\n",
            "Epoch 166/200\n",
            "\n",
            "Epoch 166: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3529 - accuracy: 0.8707 - val_loss: 0.4753 - val_accuracy: 0.8305 - 2s/epoch - 307ms/step\n",
            "Epoch 167/200\n",
            "\n",
            "Epoch 167: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3387 - accuracy: 0.8707 - val_loss: 0.4104 - val_accuracy: 0.8475 - 2s/epoch - 307ms/step\n",
            "Epoch 168/200\n",
            "\n",
            "Epoch 168: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3434 - accuracy: 0.8491 - val_loss: 0.3942 - val_accuracy: 0.8475 - 2s/epoch - 308ms/step\n",
            "Epoch 169/200\n",
            "\n",
            "Epoch 169: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3561 - accuracy: 0.8319 - val_loss: 0.3856 - val_accuracy: 0.8305 - 2s/epoch - 305ms/step\n",
            "Epoch 170/200\n",
            "\n",
            "Epoch 170: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3469 - accuracy: 0.8621 - val_loss: 0.4485 - val_accuracy: 0.7627 - 2s/epoch - 310ms/step\n",
            "Epoch 171/200\n",
            "\n",
            "Epoch 171: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3478 - accuracy: 0.8621 - val_loss: 0.4070 - val_accuracy: 0.8136 - 2s/epoch - 306ms/step\n",
            "Epoch 172/200\n",
            "\n",
            "Epoch 172: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3490 - accuracy: 0.8621 - val_loss: 0.3934 - val_accuracy: 0.8475 - 2s/epoch - 308ms/step\n",
            "Epoch 173/200\n",
            "\n",
            "Epoch 173: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3477 - accuracy: 0.8276 - val_loss: 0.3883 - val_accuracy: 0.8305 - 2s/epoch - 308ms/step\n",
            "Epoch 174/200\n",
            "\n",
            "Epoch 174: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3488 - accuracy: 0.8621 - val_loss: 0.4294 - val_accuracy: 0.8644 - 2s/epoch - 305ms/step\n",
            "Epoch 175/200\n",
            "\n",
            "Epoch 175: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3729 - accuracy: 0.8362 - val_loss: 0.4558 - val_accuracy: 0.8305 - 2s/epoch - 307ms/step\n",
            "Epoch 176/200\n",
            "\n",
            "Epoch 176: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3492 - accuracy: 0.8621 - val_loss: 0.4180 - val_accuracy: 0.8305 - 2s/epoch - 308ms/step\n",
            "Epoch 177/200\n",
            "\n",
            "Epoch 177: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3434 - accuracy: 0.8578 - val_loss: 0.4230 - val_accuracy: 0.8475 - 2s/epoch - 307ms/step\n",
            "Epoch 178/200\n",
            "\n",
            "Epoch 178: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3608 - accuracy: 0.8491 - val_loss: 0.4226 - val_accuracy: 0.7966 - 2s/epoch - 308ms/step\n",
            "Epoch 179/200\n",
            "\n",
            "Epoch 179: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3509 - accuracy: 0.8621 - val_loss: 0.4561 - val_accuracy: 0.8136 - 2s/epoch - 310ms/step\n",
            "Epoch 180/200\n",
            "\n",
            "Epoch 180: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3266 - accuracy: 0.8922 - val_loss: 0.3983 - val_accuracy: 0.8305 - 2s/epoch - 309ms/step\n",
            "Epoch 181/200\n",
            "\n",
            "Epoch 181: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3482 - accuracy: 0.8578 - val_loss: 0.4254 - val_accuracy: 0.8305 - 2s/epoch - 310ms/step\n",
            "Epoch 182/200\n",
            "\n",
            "Epoch 182: val_loss did not improve from 0.37293\n",
            "8/8 - 3s - loss: 0.3501 - accuracy: 0.8621 - val_loss: 0.4071 - val_accuracy: 0.8644 - 3s/epoch - 313ms/step\n",
            "Epoch 183/200\n",
            "\n",
            "Epoch 183: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3350 - accuracy: 0.8707 - val_loss: 0.4033 - val_accuracy: 0.8475 - 2s/epoch - 305ms/step\n",
            "Epoch 184/200\n",
            "\n",
            "Epoch 184: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3425 - accuracy: 0.8707 - val_loss: 0.4422 - val_accuracy: 0.8644 - 2s/epoch - 306ms/step\n",
            "Epoch 185/200\n",
            "\n",
            "Epoch 185: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3306 - accuracy: 0.8664 - val_loss: 0.5183 - val_accuracy: 0.7966 - 2s/epoch - 310ms/step\n",
            "Epoch 186/200\n",
            "\n",
            "Epoch 186: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3365 - accuracy: 0.8707 - val_loss: 0.5199 - val_accuracy: 0.7627 - 2s/epoch - 306ms/step\n",
            "Epoch 187/200\n",
            "\n",
            "Epoch 187: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3332 - accuracy: 0.8922 - val_loss: 0.4491 - val_accuracy: 0.8475 - 2s/epoch - 307ms/step\n",
            "Epoch 188/200\n",
            "\n",
            "Epoch 188: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3232 - accuracy: 0.8836 - val_loss: 0.4115 - val_accuracy: 0.8136 - 2s/epoch - 308ms/step\n",
            "Epoch 189/200\n",
            "\n",
            "Epoch 189: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3324 - accuracy: 0.8750 - val_loss: 0.3946 - val_accuracy: 0.8305 - 2s/epoch - 308ms/step\n",
            "Epoch 190/200\n",
            "\n",
            "Epoch 190: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3509 - accuracy: 0.8491 - val_loss: 0.4285 - val_accuracy: 0.8136 - 2s/epoch - 309ms/step\n",
            "Epoch 191/200\n",
            "\n",
            "Epoch 191: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3356 - accuracy: 0.8664 - val_loss: 0.4176 - val_accuracy: 0.8475 - 2s/epoch - 309ms/step\n",
            "Epoch 192/200\n",
            "\n",
            "Epoch 192: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3302 - accuracy: 0.8707 - val_loss: 0.3809 - val_accuracy: 0.8305 - 2s/epoch - 311ms/step\n",
            "Epoch 193/200\n",
            "\n",
            "Epoch 193: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3373 - accuracy: 0.8664 - val_loss: 0.3859 - val_accuracy: 0.8305 - 2s/epoch - 307ms/step\n",
            "Epoch 194/200\n",
            "\n",
            "Epoch 194: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3372 - accuracy: 0.8448 - val_loss: 0.3893 - val_accuracy: 0.8305 - 2s/epoch - 307ms/step\n",
            "Epoch 195/200\n",
            "\n",
            "Epoch 195: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3273 - accuracy: 0.8578 - val_loss: 0.4216 - val_accuracy: 0.8475 - 2s/epoch - 309ms/step\n",
            "Epoch 196/200\n",
            "\n",
            "Epoch 196: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3209 - accuracy: 0.8664 - val_loss: 0.4327 - val_accuracy: 0.8305 - 2s/epoch - 309ms/step\n",
            "Epoch 197/200\n",
            "\n",
            "Epoch 197: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3383 - accuracy: 0.8750 - val_loss: 0.4313 - val_accuracy: 0.8305 - 2s/epoch - 310ms/step\n",
            "Epoch 198/200\n",
            "\n",
            "Epoch 198: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3353 - accuracy: 0.8664 - val_loss: 0.4672 - val_accuracy: 0.7966 - 2s/epoch - 309ms/step\n",
            "Epoch 199/200\n",
            "\n",
            "Epoch 199: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3350 - accuracy: 0.8664 - val_loss: 0.4617 - val_accuracy: 0.8305 - 2s/epoch - 307ms/step\n",
            "Epoch 200/200\n",
            "\n",
            "Epoch 200: val_loss did not improve from 0.37293\n",
            "8/8 - 2s - loss: 0.3250 - accuracy: 0.8750 - val_loss: 0.4494 - val_accuracy: 0.8305 - 2s/epoch - 305ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "8Dhuy7ZPuVRs"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "Mq6DTEhyuRfK",
        "outputId": "985684fc-9faa-47f7-bafc-27099ac08495"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict"
      ],
      "metadata": {
        "id": "R_qS9ik1y9S3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('/content/tmp/checkpoint.h5')\n",
        "probs = model.predict(X1_test)"
      ],
      "metadata": {
        "id": "3zorV52Py_WU"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Result"
      ],
      "metadata": {
        "id": "Q8H8y_9xy_7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def report(thres):\n",
        "    y_pred =(probs>thres)\n",
        "    print(y_pred[:,-1].astype(int))\n",
        "    print(classification_report(y1_test, y_pred))\n",
        "    return classification_report(y1_test, y_pred)"
      ],
      "metadata": {
        "id": "Gjl-FPd4zCZJ"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report(0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "It65Gx1lDFKG",
        "outputId": "24689a12-9afe-4dcf-a379-b216b7906d33"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0\n",
            " 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
            " 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.08      0.13        96\n",
            "           1       0.60      0.88      0.71       153\n",
            "\n",
            "   micro avg       0.57      0.57      0.57       249\n",
            "   macro avg       0.45      0.48      0.42       249\n",
            "weighted avg       0.49      0.57      0.49       249\n",
            " samples avg       0.57      0.57      0.57       249\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'              precision    recall  f1-score   support\\n\\n           0       0.30      0.08      0.13        96\\n           1       0.60      0.88      0.71       153\\n\\n   micro avg       0.57      0.57      0.57       249\\n   macro avg       0.45      0.48      0.42       249\\nweighted avg       0.49      0.57      0.49       249\\n samples avg       0.57      0.57      0.57       249\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('readme.txt', 'a') as f:\n",
        "    f.write(' '.join(channels3))\n",
        "    f.write('\\n')\n",
        "    f.write(report(0.5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SKiSVTpETlj",
        "outputId": "7853badd-7aa1-4e1b-91b1-a7d71026ba26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 1 1 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 0 1 1 0 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 0\n",
            " 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.50      0.65        40\n",
            "           1       0.73      0.96      0.83        57\n",
            "\n",
            "   micro avg       0.77      0.77      0.77        97\n",
            "   macro avg       0.82      0.73      0.74        97\n",
            "weighted avg       0.81      0.77      0.76        97\n",
            " samples avg       0.77      0.77      0.77        97\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
      ],
      "metadata": {
        "id": "qXrAL4wf-Q_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import decomposition, datasets\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn import svm\n",
        "\n",
        "svc = svm.SVC()\n",
        "# pca = decomposition.PCA()\n",
        "\n",
        "# pipe = Pipeline(steps=[('pca', pca), ('svc', svc)])\n"
      ],
      "metadata": {
        "id": "2dDVPrJ8E98p"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X1, y1= getData(loadData(1), pick_channels=channels3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSEJkK57k0Xe",
        "outputId": "680715b1-98f3-4eab-e072-9f44ae33a811"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading /content/drive/MyDrive/ERN-Data/sub-001/eeg/sub-001_task-ERN_eeg.fdt\n",
            "Adding metadata with 14 columns\n",
            "Replacing existing metadata with 14 columns\n",
            "388 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "0 projection items activated\n",
            "Loading data for 388 events and 1025 original time points ...\n",
            "    Rejecting  epoch based on EEG : ['FP1', 'FP2', 'F8', 'VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['FP2', 'F4', 'F8', 'C6', 'HEOG_left', 'HEOG_right', 'VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['F8']\n",
            "    Rejecting  epoch based on EEG : ['FP1', 'FP2', 'VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['FP2', 'F8', 'VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['FP1', 'F7', 'FP2', 'F8', 'VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['F8']\n",
            "    Rejecting  epoch based on EEG : ['F8']\n",
            "    Rejecting  epoch based on EEG : ['F8']\n",
            "    Rejecting  epoch based on EEG : ['VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['FP2', 'F8', 'VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['FP2', 'F8', 'HEOG_right']\n",
            "    Rejecting  epoch based on EEG : ['FP1', 'FP2', 'VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['F8']\n",
            "    Rejecting  epoch based on EEG : ['FP1', 'F7', 'P7', 'FP2', 'F4', 'F8', 'P8', 'PO8', 'VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['F8', 'PO8']\n",
            "    Rejecting  epoch based on EEG : ['F8']\n",
            "    Rejecting  epoch based on EEG : ['F8']\n",
            "    Rejecting  epoch based on EEG : ['F8', 'HEOG_right', 'VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['FP1', 'F7', 'FP2', 'F8', 'VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['FP1', 'FP2', 'F4', 'F8', 'HEOG_right', 'VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['FP1', 'F3', 'F7', 'O1', 'Oz', 'FP2', 'F4', 'F8', 'P8', 'VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['FP1', 'F7', 'FP2', 'F4', 'F8', 'VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['FP1', 'F7', 'P9', 'FP2', 'F4', 'F8', 'FC4', 'C4', 'C6', 'P4', 'HEOG_right', 'VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['FP1', 'F7', 'F8', 'C6', 'HEOG_right', 'VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['FP1', 'FP2', 'VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['FP1', 'FP2', 'F8', 'VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['FP1', 'FP2', 'F8', 'HEOG_right', 'VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['FP1', 'F7', 'FP2', 'F4', 'F8', 'PO8', 'HEOG_left', 'HEOG_right', 'VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['FP1', 'FP2', 'F4', 'F8', 'HEOG_left', 'HEOG_right', 'VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['FP1', 'FP2', 'F4', 'F8', 'HEOG_left', 'HEOG_right', 'VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['FP1', 'F7', 'FP2', 'F4', 'F8', 'HEOG_left', 'HEOG_right', 'VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['F8']\n",
            "    Rejecting  epoch based on EEG : ['F8']\n",
            "    Rejecting  epoch based on EEG : ['FP2', 'F8']\n",
            "    Rejecting  epoch based on EEG : ['VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['F8']\n",
            "    Rejecting  epoch based on EEG : ['F3', 'F7', 'FC3', 'C5', 'PO7', 'F8', 'PO8', 'HEOG_left', 'VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['F7', 'F8']\n",
            "    Rejecting  epoch based on EEG : ['HEOG_right']\n",
            "    Rejecting  epoch based on EEG : ['FP1', 'FP2', 'F8']\n",
            "    Rejecting  epoch based on EEG : ['FP1', 'FP2', 'F4', 'F8', 'VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['FP1', 'FP2', 'F4', 'F8', 'VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['F7', 'FP2', 'F8']\n",
            "    Rejecting  epoch based on EEG : ['FP1', 'FP2', 'F8', 'HEOG_right', 'VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['F8']\n",
            "    Rejecting  epoch based on EEG : ['F3', 'F7', 'FC3', 'C5', 'F4', 'F8', 'C6', 'HEOG_left']\n",
            "    Rejecting  epoch based on EEG : ['F7']\n",
            "    Rejecting  epoch based on EEG : ['F7']\n",
            "    Rejecting  epoch based on EEG : ['VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['F7']\n",
            "    Rejecting  epoch based on EEG : ['F8']\n",
            "    Rejecting  epoch based on EEG : ['F8']\n",
            "    Rejecting  epoch based on EEG : ['FP1', 'FP2', 'VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['FP1', 'FP2', 'F8', 'HEOG_right', 'VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['FP1', 'F7', 'FP2', 'F4', 'F8', 'FC4', 'O2', 'HEOG_right', 'VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['FP1', 'F7', 'P7', 'P9', 'PO7', 'O1', 'Oz', 'CPz', 'FP2', 'F8', 'C6', 'P4', 'P8', 'P10', 'PO8', 'PO4', 'O2', 'HEOG_left', 'HEOG_right']\n",
            "    Rejecting  epoch based on EEG : ['FP1', 'F3', 'F7', 'FC3', 'C3', 'C5', 'P7', 'P9', 'PO3', 'O1', 'Oz', 'Pz', 'CPz', 'FP2', 'Fz', 'F4', 'F8', 'FC4', 'FCz', 'Cz', 'C4', 'C6', 'P4', 'P8', 'P10', 'PO8', 'PO4', 'O2', 'HEOG_left', 'HEOG_right', 'VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['FP1', 'P7', 'PO3', 'O1', 'Oz', 'FP2', 'F4', 'F8', 'FC4', 'P8', 'P10', 'PO4', 'O2', 'HEOG_left', 'VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['FP1', 'Oz', 'FP2', 'F8', 'P8', 'P10', 'PO8', 'PO4', 'HEOG_right', 'VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['Oz', 'FP2', 'F8', 'P8', 'PO8', 'PO4']\n",
            "    Rejecting  epoch based on EEG : ['F8']\n",
            "    Rejecting  epoch based on EEG : ['P8']\n",
            "    Rejecting  epoch based on EEG : ['C6', 'P8']\n",
            "    Rejecting  epoch based on EEG : ['F8']\n",
            "    Rejecting  epoch based on EEG : ['F8']\n",
            "    Rejecting  epoch based on EEG : ['F8']\n",
            "    Rejecting  epoch based on EEG : ['F8']\n",
            "    Rejecting  epoch based on EEG : ['F8']\n",
            "    Rejecting  epoch based on EEG : ['F8']\n",
            "    Rejecting  epoch based on EEG : ['F8']\n",
            "    Rejecting  epoch based on EEG : ['F8']\n",
            "    Rejecting  epoch based on EEG : ['FP2']\n",
            "    Rejecting  epoch based on EEG : ['F8']\n",
            "    Rejecting  epoch based on EEG : ['FP2', 'F8']\n",
            "    Rejecting  epoch based on EEG : ['F8']\n",
            "    Rejecting  epoch based on EEG : ['FP2', 'F8']\n",
            "    Rejecting  epoch based on EEG : ['FP2', 'F8', 'VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['FP1', 'FP2', 'F8', 'VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['F8']\n",
            "    Rejecting  epoch based on EEG : ['F8']\n",
            "    Rejecting  epoch based on EEG : ['F8']\n",
            "    Rejecting  epoch based on EEG : ['F8']\n",
            "    Rejecting  epoch based on EEG : ['P7', 'PO7', 'F8', 'P8', 'PO8', 'O2']\n",
            "    Rejecting  epoch based on EEG : ['P7', 'PO7', 'F8', 'PO8']\n",
            "    Rejecting  epoch based on EEG : ['F8']\n",
            "    Rejecting  epoch based on EEG : ['F8', 'PO8']\n",
            "    Rejecting  epoch based on EEG : ['F8', 'PO8']\n",
            "    Rejecting  epoch based on EEG : ['F8', 'PO8']\n",
            "    Rejecting  epoch based on EEG : ['F8', 'PO8']\n",
            "    Rejecting  epoch based on EEG : ['P7', 'PO7', 'FP2', 'F8', 'PO8', 'PO4', 'O2']\n",
            "    Rejecting  epoch based on EEG : ['F8', 'PO8']\n",
            "    Rejecting  epoch based on EEG : ['P7', 'PO7', 'F4', 'F8', 'PO8', 'O2']\n",
            "    Rejecting  epoch based on EEG : ['PO7', 'O1', 'F8', 'PO8', 'PO4', 'O2']\n",
            "    Rejecting  epoch based on EEG : ['PO7', 'F8', 'PO8', 'O2']\n",
            "    Rejecting  epoch based on EEG : ['F8', 'PO8', 'O2']\n",
            "    Rejecting  epoch based on EEG : ['F8', 'PO8']\n",
            "    Rejecting  epoch based on EEG : ['PO7', 'O1', 'F8', 'PO8', 'O2']\n",
            "    Rejecting  epoch based on EEG : ['F8', 'PO8']\n",
            "    Rejecting  epoch based on EEG : ['F8']\n",
            "    Rejecting  epoch based on EEG : ['F8']\n",
            "    Rejecting  epoch based on EEG : ['FP2', 'F8']\n",
            "    Rejecting  epoch based on EEG : ['P7', 'PO7', 'O1', 'F8', 'PO8', 'VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['FP1', 'FP2', 'F8']\n",
            "    Rejecting  epoch based on EEG : ['FP2', 'F8', 'PO8', 'VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['F8']\n",
            "    Rejecting  epoch based on EEG : ['FP2', 'F8', 'VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['FP1', 'FP2', 'F8', 'HEOG_right', 'VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['F8']\n",
            "    Rejecting  epoch based on EEG : ['F8']\n",
            "    Rejecting  epoch based on EEG : ['F8']\n",
            "    Rejecting  epoch based on EEG : ['F8']\n",
            "    Rejecting  epoch based on EEG : ['F8']\n",
            "    Rejecting  epoch based on EEG : ['F8']\n",
            "    Rejecting  epoch based on EEG : ['F8']\n",
            "    Rejecting  epoch based on EEG : ['FP1', 'F3', 'F7', 'FC3', 'C3', 'C5', 'FP2', 'F4', 'F8', 'FC4', 'C4', 'C6', 'HEOG_left', 'HEOG_right', 'VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['FP1', 'F3', 'F7', 'FC3', 'C3', 'C5', 'FP2', 'Fz', 'F4', 'F8', 'FC4', 'C4', 'C6', 'HEOG_left', 'HEOG_right', 'VEOG_lower']\n",
            "    Rejecting  epoch based on EEG : ['F3', 'F7', 'FC3', 'C3', 'C5', 'FP2', 'F4', 'F8', 'FC4', 'C4', 'C6', 'HEOG_left', 'HEOG_right']\n",
            "    Rejecting  epoch based on EEG : ['F7', 'F4', 'F8', 'FC4', 'C6', 'HEOG_right']\n",
            "    Rejecting  epoch based on EEG : ['F7', 'F4', 'F8', 'FC4', 'C6', 'HEOG_right']\n",
            "    Rejecting  epoch based on EEG : ['F7', 'F4', 'F8', 'FC4', 'C6']\n",
            "    Rejecting  epoch based on EEG : ['F3', 'F7', 'F4', 'F8', 'FC4', 'C6', 'HEOG_right']\n",
            "    Rejecting  epoch based on EEG : ['F7', 'F4', 'F8', 'FC4', 'C6']\n",
            "    Rejecting  epoch based on EEG : ['F7', 'F8', 'FC4']\n",
            "    Rejecting  epoch based on EEG : ['F7', 'F8', 'FC4']\n",
            "    Rejecting  epoch based on EEG : ['F7', 'F4', 'F8', 'FC4', 'C6']\n",
            "    Rejecting  epoch based on EEG : ['F7', 'F4', 'F8', 'FC4', 'C6']\n",
            "    Rejecting  epoch based on EEG : ['F7', 'F8']\n",
            "    Rejecting  epoch based on EEG : ['F7', 'F8']\n",
            "    Rejecting  epoch based on EEG : ['F7', 'F8']\n",
            "    Rejecting  epoch based on EEG : ['F7', 'F4', 'F8', 'FC4']\n",
            "    Rejecting  epoch based on EEG : ['F7', 'F4', 'F8', 'FC4']\n",
            "    Rejecting  epoch based on EEG : ['F7', 'F8']\n",
            "    Rejecting  epoch based on EEG : ['F7', 'F8', 'C6']\n",
            "    Rejecting  epoch based on EEG : ['F7', 'F8', 'FC4']\n",
            "    Rejecting  epoch based on EEG : ['F7', 'F8']\n",
            "    Rejecting  epoch based on EEG : ['F7', 'F8']\n",
            "    Rejecting  epoch based on EEG : ['F7', 'F8', 'FC4']\n",
            "    Rejecting  epoch based on EEG : ['F7', 'F8', 'FC4']\n",
            "139 bad epochs dropped\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X1_test =  X1.reshape(X1.shape[0], chans, samples, kernels)\n",
        "y1_test = np_utils.to_categorical(y1)"
      ],
      "metadata": {
        "id": "QFxhSAoDs2aE"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a= X.reshape((X.shape[0], X.shape[1]*X.shape[2]))"
      ],
      "metadata": {
        "id": "yyAOWjOgFh4G"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjHz9f27b1md",
        "outputId": "f1d7c7e6-0933-4139-d319-a431f573acca"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 5.85975610e-07,  1.67972561e-06,  7.10975610e-07, ...,\n",
              "        -1.55044207e-05, -1.61919207e-05, -1.64419207e-05],\n",
              "       [ 1.86605183e-05,  8.59801829e-06,  4.97301829e-06, ...,\n",
              "         1.34791159e-05,  1.65103659e-05,  1.62916159e-05],\n",
              "       [-3.18475610e-06, -1.52850610e-06, -1.59100610e-06, ...,\n",
              "        -1.77713415e-06, -2.08963415e-06, -1.71463415e-06],\n",
              "       ...,\n",
              "       [ 1.47131193e-05,  1.05256193e-05,  7.11936928e-06, ...,\n",
              "        -9.46295732e-06, -7.96295732e-06, -7.36920732e-06],\n",
              "       [ 1.38573742e-06,  2.04198742e-06,  2.41698742e-06, ...,\n",
              "        -7.99542683e-06, -9.43292683e-06, -1.07141768e-05],\n",
              "       [ 2.25872618e-05,  2.19935118e-05,  2.18685118e-05, ...,\n",
              "        -1.17179878e-05, -1.19992378e-05, -1.35929878e-05]])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svc.fit(a,y)"
      ],
      "metadata": {
        "id": "vQwGbL2ZFje1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f612680-412a-431e-a1ec-5b4e62c2b081"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC()"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bmSfe6cFt4W",
        "outputId": "3ce26baf-876c-4dd3-c155-ed983caf7771"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(388, 16400)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "8JL7wVQYdo2f"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pT0zuoVklOcE",
        "outputId": "766dd682-df55-47e1-eb1f-03d62b19e301"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(388, 16, 1025)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrXNNSiXla9V",
        "outputId": "917b6e7a-5e07-4ae8-966a-3f7a7033488f"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(388, 16, 1025)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probs = svc.predict(X1.reshape((X1.shape[0], X.shape[1]*X.shape[2])))\n",
        "# y_val = np.argmax(y_val, axis=1)"
      ],
      "metadata": {
        "id": "xi7nWJMNeHYn"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kV9RCaM0pBsx",
        "outputId": "ecd6b7a4-6e36-4dda-c32e-d82aeeeb5a52"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Onje-YF0p4Y-",
        "outputId": "d12f7966-3264-4872-9609-4b7973a61c25"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
              "       0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
              "       1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0,\n",
              "       1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
              "       1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
              "       0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
              "       1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1,\n",
              "       1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(probs,y1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKFCyorwcjUA",
        "outputId": "aeb2e9ad-8682-4ca5-9004-66e28fa9f44f"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.01      0.40      0.03         5\n",
            "           1       0.99      0.64      0.78       383\n",
            "\n",
            "    accuracy                           0.64       388\n",
            "   macro avg       0.50      0.52      0.40       388\n",
            "weighted avg       0.98      0.64      0.77       388\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit_transform(X,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "RhK_G9R6IM79",
        "outputId": "880e1280-830f-4ab8-e637-9de3e926016e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-173-0f8635be22ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    853\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    543\u001b[0m         \"\"\"\n\u001b[1;32m    544\u001b[0m         X, y = self._validate_data(\n\u001b[0;32m--> 545\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m         )\n\u001b[1;32m    547\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m         \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m     )\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    794\u001b[0m             raise ValueError(\n\u001b[1;32m    795\u001b[0m                 \u001b[0;34m\"Found array with dim %d. %s expected <= 2.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m                 \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    797\u001b[0m             )\n\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found array with dim 4. LinearDiscriminantAnalysis expected <= 2."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7Ljf7rOAwFiO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}